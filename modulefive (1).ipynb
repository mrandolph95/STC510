{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce4dec4e-74df-440d-8755-fef74218322b",
   "metadata": {
    "tags": []
   },
   "source": [
    "1. Parse, clean, and organize the Jeopardy! question data file to train a Naive Bayesian classifier.\n",
    "\n",
    "Just as we have built a classifier above, your aim here is to make sense of the data presented and create a binary classifier (\"high value\" and \"low value,\" based on the points available for each) for questions. Despite the large number of questions, this is an extraordinarily difficult classification problem. Consider it as a human coder: how often could you tell those questions that are \"easy\" versus \"hard\"? The degree to which you are successful in this is largely based on your own contextual knowledge--indeed, you might be tempted to classify questions you know the answer to as \"easy\" and those you do not as \"hard.\" The computer doesn't know the answers to any of these.\n",
    "\n",
    "For that reason, do not be discouraged if your classifier does not perform well. This constitutes an especially difficult problem for a simple classifier to solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "821e35ea-dc49-4d66-a5f7-3146e5b74b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbe3a637-4895-448a-aa98-0c20f73947b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd1a1b4d-db54-4df1-a463-8d7be2d4986d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48d4fb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64996c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38f59243-26f4-4b73-a197-405818304823",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/malirandolph/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da3986e7-ad69-4aa2-bde3-0cec0bdbe8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48635183-c077-4559-9275-3ab825a9e2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/malirandolph/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b59f6d",
   "metadata": {},
   "source": [
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7f3402",
   "metadata": {},
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "f503957d-8821-4e99-92db-b285b428e1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/malirandolph/Downloads/jeopardy.json', 'r', newline='\\r\\n') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "dda9cfec-de6c-4f59-b81a-94bc9f2f6b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts json file to csv\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "98025e84-219c-4818-9fae-b2cb87078e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('modfive.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d4405a8c-de38-4697-b658-2d935ec00c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('modfive.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8ad77dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216930"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1221a46d",
   "metadata": {},
   "source": [
    "# removing dollar signs from value column so we can convert inputs to floats\n",
    "df['value'] = df['value'].map(str).str.replace('$','').str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "9915399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning the rounds a value\n",
    "df['round'] = df['round'].apply(lambda x: 1 if x==\"Jeopardy!\" else 0 if x==\"Double Jeopardy!\" else -1).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "78db376b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"question\"] = df[\"question\"].replace(\",\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "2fe3b776",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"question\"] = df[\"question\"].replace(\":\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b1b3c912",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"question\"] = df[\"question\"].replace(\";\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f64e0ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/df/z6m4t_kj47s4qtpl7pfk3fgw0000gn/T/ipykernel_59945/2485659254.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['question'] = df['question'].str.replace('\\d+', '')\n"
     ]
    }
   ],
   "source": [
    "df['question'] = df['question'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "beb0f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['question'] = df['question'].replace(to_replace=r'^https?:\\/\\/.*[\\r\\n]*',value='',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "0feabcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['question'] = df['question'].str.rstrip('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "04b68aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['question'] = df['question'].replace('\"', '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebe7fbf",
   "metadata": {},
   "source": [
    "removes all punctuation from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "caadfa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/df/z6m4t_kj47s4qtpl7pfk3fgw0000gn/T/ipykernel_59945/3651572173.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['question'] = df['question'].str.replace(r'[^\\w\\s]+', '')\n"
     ]
    }
   ],
   "source": [
    "df['question'] = df['question'].str.replace(r'[^\\w\\s]+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "192985e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['round', 'question']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6d0e8819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>air_date</th>\n",
       "      <th>question</th>\n",
       "      <th>value</th>\n",
       "      <th>answer</th>\n",
       "      <th>round</th>\n",
       "      <th>show_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HISTORY</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>For the last  years of his life Galileo was un...</td>\n",
       "      <td>$200</td>\n",
       "      <td>Copernicus</td>\n",
       "      <td>1</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>No   Olympian football star at Carlisle Indian...</td>\n",
       "      <td>$200</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "      <td>1</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>$200</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>1</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>In  live on The Art Linkletter Show this compa...</td>\n",
       "      <td>$200</td>\n",
       "      <td>McDonald\\'s</td>\n",
       "      <td>1</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Signer of the Dec of Indep framer of the Const...</td>\n",
       "      <td>$200</td>\n",
       "      <td>John Adams</td>\n",
       "      <td>1</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3-LETTER WORDS</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>In the title of an Aesop fable this insect sha...</td>\n",
       "      <td>$200</td>\n",
       "      <td>the ant</td>\n",
       "      <td>1</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HISTORY</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Built in  BC to link Rome  the South of Italy ...</td>\n",
       "      <td>$400</td>\n",
       "      <td>the Appian Way</td>\n",
       "      <td>1</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>No   steals for the Birmingham Barons  steals ...</td>\n",
       "      <td>$400</td>\n",
       "      <td>Michael Jordan</td>\n",
       "      <td>1</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>In the winter of  a record  inches of snow fel...</td>\n",
       "      <td>$400</td>\n",
       "      <td>Washington</td>\n",
       "      <td>1</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>This housewares store was named for the packag...</td>\n",
       "      <td>$400</td>\n",
       "      <td>Crate &amp; Barrel</td>\n",
       "      <td>1</td>\n",
       "      <td>4680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          category    air_date  \\\n",
       "0                          HISTORY  2004-12-31   \n",
       "1  ESPN's TOP 10 ALL-TIME ATHLETES  2004-12-31   \n",
       "2      EVERYBODY TALKS ABOUT IT...  2004-12-31   \n",
       "3                 THE COMPANY LINE  2004-12-31   \n",
       "4              EPITAPHS & TRIBUTES  2004-12-31   \n",
       "5                   3-LETTER WORDS  2004-12-31   \n",
       "6                          HISTORY  2004-12-31   \n",
       "7  ESPN's TOP 10 ALL-TIME ATHLETES  2004-12-31   \n",
       "8      EVERYBODY TALKS ABOUT IT...  2004-12-31   \n",
       "9                 THE COMPANY LINE  2004-12-31   \n",
       "\n",
       "                                            question value          answer  \\\n",
       "0  For the last  years of his life Galileo was un...  $200      Copernicus   \n",
       "1  No   Olympian football star at Carlisle Indian...  $200      Jim Thorpe   \n",
       "2  The city of Yuma in this state has a record av...  $200         Arizona   \n",
       "3  In  live on The Art Linkletter Show this compa...  $200     McDonald\\'s   \n",
       "4  Signer of the Dec of Indep framer of the Const...  $200      John Adams   \n",
       "5  In the title of an Aesop fable this insect sha...  $200         the ant   \n",
       "6  Built in  BC to link Rome  the South of Italy ...  $400  the Appian Way   \n",
       "7  No   steals for the Birmingham Barons  steals ...  $400  Michael Jordan   \n",
       "8  In the winter of  a record  inches of snow fel...  $400      Washington   \n",
       "9  This housewares store was named for the packag...  $400  Crate & Barrel   \n",
       "\n",
       "  round  show_number  \n",
       "0     1         4680  \n",
       "1     1         4680  \n",
       "2     1         4680  \n",
       "3     1         4680  \n",
       "4     1         4680  \n",
       "5     1         4680  \n",
       "6     1         4680  \n",
       "7     1         4680  \n",
       "8     1         4680  \n",
       "9     1         4680  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "5e772a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized_text'] = df['question'].apply(word_tokenize) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "159e30ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert each word into a column\n",
    "listss = pd.DataFrame(df.tokenized_text.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "8836451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "listss = listss.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "cc70b3f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For</td>\n",
       "      <td>the</td>\n",
       "      <td>last</td>\n",
       "      <td>years</td>\n",
       "      <td>of</td>\n",
       "      <td>his</td>\n",
       "      <td>life</td>\n",
       "      <td>Galileo</td>\n",
       "      <td>was</td>\n",
       "      <td>under</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>Olympian</td>\n",
       "      <td>football</td>\n",
       "      <td>star</td>\n",
       "      <td>at</td>\n",
       "      <td>Carlisle</td>\n",
       "      <td>Indian</td>\n",
       "      <td>School</td>\n",
       "      <td>MLB</td>\n",
       "      <td>seasons</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The</td>\n",
       "      <td>city</td>\n",
       "      <td>of</td>\n",
       "      <td>Yuma</td>\n",
       "      <td>in</td>\n",
       "      <td>this</td>\n",
       "      <td>state</td>\n",
       "      <td>has</td>\n",
       "      <td>a</td>\n",
       "      <td>record</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In</td>\n",
       "      <td>live</td>\n",
       "      <td>on</td>\n",
       "      <td>The</td>\n",
       "      <td>Art</td>\n",
       "      <td>Linkletter</td>\n",
       "      <td>Show</td>\n",
       "      <td>this</td>\n",
       "      <td>company</td>\n",
       "      <td>served</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Signer</td>\n",
       "      <td>of</td>\n",
       "      <td>the</td>\n",
       "      <td>Dec</td>\n",
       "      <td>of</td>\n",
       "      <td>Indep</td>\n",
       "      <td>framer</td>\n",
       "      <td>of</td>\n",
       "      <td>the</td>\n",
       "      <td>Constitution</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216925</th>\n",
       "      <td>This</td>\n",
       "      <td>Puccini</td>\n",
       "      <td>opera</td>\n",
       "      <td>turns</td>\n",
       "      <td>on</td>\n",
       "      <td>the</td>\n",
       "      <td>solution</td>\n",
       "      <td>to</td>\n",
       "      <td>riddles</td>\n",
       "      <td>posed</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216926</th>\n",
       "      <td>In</td>\n",
       "      <td>North</td>\n",
       "      <td>America</td>\n",
       "      <td>this</td>\n",
       "      <td>term</td>\n",
       "      <td>is</td>\n",
       "      <td>properly</td>\n",
       "      <td>applied</td>\n",
       "      <td>to</td>\n",
       "      <td>only</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216927</th>\n",
       "      <td>In</td>\n",
       "      <td>Penny</td>\n",
       "      <td>Lane</td>\n",
       "      <td>where</td>\n",
       "      <td>this</td>\n",
       "      <td>Hellraiser</td>\n",
       "      <td>grew</td>\n",
       "      <td>up</td>\n",
       "      <td>the</td>\n",
       "      <td>barber</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216928</th>\n",
       "      <td>From</td>\n",
       "      <td>Ft</td>\n",
       "      <td>Sill</td>\n",
       "      <td>Okla</td>\n",
       "      <td>he</td>\n",
       "      <td>made</td>\n",
       "      <td>the</td>\n",
       "      <td>plea</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>is</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216929</th>\n",
       "      <td>A</td>\n",
       "      <td>silent</td>\n",
       "      <td>movie</td>\n",
       "      <td>title</td>\n",
       "      <td>includes</td>\n",
       "      <td>the</td>\n",
       "      <td>last</td>\n",
       "      <td>name</td>\n",
       "      <td>of</td>\n",
       "      <td>this</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216930 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2      3         4           5         6    \\\n",
       "0          For       the      last  years        of         his      life   \n",
       "1           No  Olympian  football   star        at    Carlisle    Indian   \n",
       "2          The      city        of   Yuma        in        this     state   \n",
       "3           In      live        on    The       Art  Linkletter      Show   \n",
       "4       Signer        of       the    Dec        of       Indep    framer   \n",
       "...        ...       ...       ...    ...       ...         ...       ...   \n",
       "216925    This   Puccini     opera  turns        on         the  solution   \n",
       "216926      In     North   America   this      term          is  properly   \n",
       "216927      In     Penny      Lane  where      this  Hellraiser      grew   \n",
       "216928    From        Ft      Sill   Okla        he        made       the   \n",
       "216929       A    silent     movie  title  includes         the      last   \n",
       "\n",
       "            7        8             9    ...   121   122   123   124   125  \\\n",
       "0       Galileo      was         under  ...  None  None  None  None  None   \n",
       "1        School      MLB       seasons  ...  None  None  None  None  None   \n",
       "2           has        a        record  ...  None  None  None  None  None   \n",
       "3          this  company        served  ...  None  None  None  None  None   \n",
       "4            of      the  Constitution  ...  None  None  None  None  None   \n",
       "...         ...      ...           ...  ...   ...   ...   ...   ...   ...   \n",
       "216925       to  riddles         posed  ...  None  None  None  None  None   \n",
       "216926  applied       to          only  ...  None  None  None  None  None   \n",
       "216927       up      the        barber  ...  None  None  None  None  None   \n",
       "216928     plea  Arizona            is  ...  None  None  None  None  None   \n",
       "216929     name       of          this  ...  None  None  None  None  None   \n",
       "\n",
       "         126   127   128   129   130  \n",
       "0       None  None  None  None  None  \n",
       "1       None  None  None  None  None  \n",
       "2       None  None  None  None  None  \n",
       "3       None  None  None  None  None  \n",
       "4       None  None  None  None  None  \n",
       "...      ...   ...   ...   ...   ...  \n",
       "216925  None  None  None  None  None  \n",
       "216926  None  None  None  None  None  \n",
       "216927  None  None  None  None  None  \n",
       "216928  None  None  None  None  None  \n",
       "216929  None  None  None  None  None  \n",
       "\n",
       "[216930 rows x 131 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "367b7884",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf = listss.dropna(axis=1,how='all', inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "5cbe8bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['round']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "771a1ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['round', 'tokenized_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0ccf8f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>round</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216925</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216926</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216927</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216928</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216929</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216930 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       round\n",
       "0          1\n",
       "1          1\n",
       "2          1\n",
       "3          1\n",
       "4          1\n",
       "...      ...\n",
       "216925     0\n",
       "216926     0\n",
       "216927     0\n",
       "216928     0\n",
       "216929    -1\n",
       "\n",
       "[216930 rows x 1 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9d6b952e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(listss, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "0b7b1052",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "1e3aca39",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/df/z6m4t_kj47s4qtpl7pfk3fgw0000gn/T/ipykernel_59945/877218194.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train_tf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1844\u001b[0m         \"\"\"\n\u001b[1;32m   1845\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1846\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1847\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1848\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1202\u001b[0;31m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[1;32m   1203\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \"\"\"\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "x_train_tf = tfidf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "aa2d59a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "c4450cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "82c54f6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2, 162697]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/df/z6m4t_kj47s4qtpl7pfk3fgw0000gn/T/ipykernel_44989/2133950101.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnaive_bayes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \"\"\"\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_class_log_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_prior\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    320\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2, 162697]"
     ]
    }
   ],
   "source": [
    "naive_bayes.fit(x_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb58049",
   "metadata": {},
   "source": [
    "countvectorizer = CountVectorizer(analyzer= 'word', stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "c48f6e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvectorizer = TfidfVectorizer(analyzer='word',stop_words= 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "0860fd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized_text'] = df['tokenized_text'].map(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "f95ee8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectors = tfidf_vectorizer.fit_transform(df['tokenized_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "66a849fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['round', 'tokenized_text']].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "54f55832",
   "metadata": {},
   "outputs": [],
   "source": [
    "as_array = tfidf_vectors.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e52c38f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tfidf_vectorizer.get_feature_names()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
